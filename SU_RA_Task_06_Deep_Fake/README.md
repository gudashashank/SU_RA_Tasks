# LLM ‚ÄúDeep Fake‚Äù Interview Project  

## 1. Background  

In previous periods, we focused on creating narratives and textual summaries of datasets.  
For example, I used seasonal statistics from **Syracuse University Women‚Äôs Lacrosse (2023‚Äì2025)** and asked an LLM to analyze performance trends and even suggest recommendations for upcoming seasons.  

This period, the task was to take that narrative and transform it into an **AI-generated ‚Äúdeep fake‚Äù interview** ‚Äî essentially turning research findings into a scripted dialogue between an interviewer and a researcher.  

We also leveraged the analysis from [SU_RA_Task_05_Descriptive_Stats](https://github.com/gudashashank/SU_RA_Task_05_Descriptive_Stats) to generate the video, ensuring that the outputs were grounded in actual data-driven insights rather than synthetic prompts alone.  

---

## 2. Process  

### Step 1: Narrative to Interview Script  
- I began with my expanded narrative about **LLM performance evaluation** on sports statistics.  
- The first attempt was to feed the entire script into a video generator in one go.  
- **Problem:** The generator capped output length (8 seconds), so the full script could not be rendered.  

### Step 2: Breaking into Individual Clips  
- I split the interview into **short, 8-second clips** (intro, key findings, limitations, conclusion).  
- Each clip was generated individually, then merged.  
- **Problem:** Continuity issues arose ‚Äî background and character settings varied slightly, creating a disjointed feel.  

### Step 3: Consistency Fix  
- To solve this, I standardized a **single scene prompt**:  
  > *A modern news-style studio with neutral colors, split-screen format showing the interviewer on the left and the researcher on the right. Professional lighting, subtle lower-third captions, no background changes.*  
- By reusing this same description for each clip, I preserved visual continuity when merging.  

---

## 3. Tools Explored  

- **Text-to-video generators:** Tried tools like **Google Veo, Grox (by X)** (free trials or limited student access).  
- **Google NotebookLM:** Used for generating both an **audio podcast** and a **video overview feature** to represent the interview in a more natural ‚Äúdeep fake‚Äù style.  
- **Video editing:** Used simple free tools to merge clips and add consistent overlays.  

---

## 4. Workflow Strategy  

1. **Write the script** ‚Üí Transform narrative into Q&A style (interviewer ‚Üî researcher).  
2. **Chunk into clips** ‚Üí 7‚Äì8 seconds each to fit generator limits.  
3. **Apply consistent scene prompt** ‚Üí Same studio setup across all clips.  
4. **Render separately** ‚Üí Generate multiple clips instead of one long video.  
5. **Merge** ‚Üí Stitch clips together in a timeline editor.  
6. **Polish** ‚Üí Add subtitles, audio, and transitions for flow.  

---

## 5. Reflections  

- **Key challenge:** Most free tools limit clip length or watermark heavily.  
- **Solution:** Chunking into multiple clips worked, but ensuring continuity required strict consistency in the scene prompt.  
- **Takeaway:** Using **Google NotebookLM‚Äôs audio and video overview features** provided a free, student-friendly alternative that produced a smoother final product.  

---

## 6. Outputs  

We produced:  
- An **audio podcast version** of the interview using **Google NotebookLM**  
- A **video overview feature** with the same tool for visual presentation  

All videos and audio will be included with timestamps for easy navigation.  

### Generated Video
<p align="center">
  <a href="https://www.youtube.com/watch?v=gqNko76nfvg" target="_blank">
    <img src="https://img.shields.io/badge/‚ñ∂Ô∏è%20Click%20Here%20to%20Watch-red?style=for-the-badge&logo=youtube&logoColor=white" alt="Watch on YouTube"/>
  </a>
</p>

<p align="center">
  <a href="https://www.youtube.com/watch?v=gqNko76nfvg" target="_blank">
    <img src="https://img.youtube.com/vi/gqNko76nfvg/maxresdefault.jpg" alt="LLM Analysis in Sports Data" width="80%">
  </a>
</p>

## ‚è±Ô∏è Timestamps

- [0:00 ‚Äì 0:39](https://www.youtube.com/watch?v=gqNko76nfvg&t=0s) ‚Üí üé• *Google Veo Generated Video (Merged)*
- [0:40 ‚Äì 14:56](https://www.youtube.com/watch?v=gqNko76nfvg&t=40s) ‚Üí üéß *Audio Podcast*
- [14:57 ‚Äì 20:10](https://www.youtube.com/watch?v=gqNko76nfvg&t=897s) ‚Üí üìπ *Video Generated by Notebook LLM*

---

## 7. Conclusion  

While the initial video workflow had technical limits, NotebookLM allowed us to create both an **audio podcast** and a **video overview** that captured the essence of a deep fake interview. The combination of outputs demonstrates how free or student resources can be leveraged effectively to simulate professional-style media.  

One of the biggest challenges we noticed is that **video generation often lacks consistency** even when using the same prompts, outputs can vary in quality, pacing, or visual style. This makes it difficult to rely on traditional GenAI video tools for a repeatable creative workflow.  

NotebookLM, however, operates in a **different league**. Instead of focusing solely on visuals, it enables a structured storytelling process where transcripts, audio, and video overviews are tightly integrated. This makes the end-to-end pipeline **more reliable, flexible, and closer to professional media production standards**, even when built with student-accessible or free-tier resources.  

By combining these approaches, we were able to **push beyond the limitations of raw generative models** and showcase how intelligent orchestration of tools like NotebookLM can elevate both the quality and consistency of AI-assisted media creation.

---
